#!/bin/bash

# This script is called by the run script. It is not intended to be called directly. To rebuild the
# container, use 'run --rebuild' with appropriate options.

usage="This script is called by the run script. It is not intended to be called directly. To rebuild the
container, use 'run --rebuild' with appropriate options."

while (( "$#" )); do
   case "$1" in
     -h|--help)
       echo -e $usage
       exit 0
       ;;
     *) # unsupported option
       echo -e $usage
       echo "Error: Unsupported flag $1" >&2
       exit 1
       ;;
   esac
done

#
# Check the environment and make sure all variables are defined
#
required_env=( uservdi hostvdi user group uid gid volume_root volume_git )
for e in ${required_env[@]}; do
    if [ -z ${!e} ]; then
        echo "ERROR: Requires environment variable '$e'. Only run this script with 'run --rebuild'."
        exit 1
    fi
done

#
# The container mounts these directories, so make sure they exist
#
git_dir="$HOME/git"
if [ ! -d $git_dir ]; then
    echo "Creating directory $git_dir..."
    mkdir $git_dir || exit 1
fi
ssh_dir="$HOME/.ssh"
if [ ! -d $ssh_dir ]; then
    echo "Creating directory $ssh_dir..."
    mkdir $ssh_dir || exit 1
fi

#
# There are compiler and coverity tools needed by the container.  These tools will be installed on the
# host and the volume will be NFS mounted to the container.
#
build_tools="$HOME/build_tools"
if [ ! -d $build_tools ]; then
    echo "Creating directory $build_tools..."
    mkdir -p $build_tools || exit 1
fi

#
# Check for ARM Developer's Studio files on the host system, and copy if not found
#
armcc="$build_tools/developmentstudio-2019.1/sw/ARMCompiler5.06u6/bin/armcc"
armcc_archive="./armcc.tar.xz"
if [ ! -x $armcc ]; then
    echo "Installing armcc toolchain..."
    tar -C $build_tools -xJf $armcc_archive || exit 1
fi

#
# Check for tools on the host system.  If not found, retrieve them from users VDI instance and
# install them.
#
host_ccx="$build_tools/vdi/ccxsw_tools"
rmt_ccx="/projects/ccxsw_tools"

# Associative array: [source_path_on_vdi]=dest_path_on_host
src_paths=( \
    $rmt_ccx/mentor_graphics/mgc-2018.070 \
    $rmt_ccx/sbl_tools \
    $rmt_ccx/contrib \
    $rmt_ccx/coverity/2022.06/Linux-64 \
)
dst_paths=( \
    $host_ccx/mentor_graphics/mgc-2018.070 \
    $host_ccx/sbl_tools \
    $host_ccx/contrib \
    $host_ccx/coverity/2022.06/Linux-64 \
)
for i in "${!src_paths[@]}"; do
    src="${src_paths[$i]}"
    dst="${dst_paths[$i]}"
    if [ ! -d $dst ]; then
        echo "Creating directory $dst..."
        mkdir -p $dst || exit 1
        #rmt_tool="$rmt_ccx/$tool"
        echo "Copying $dst from VDI..."
        ssh $uservdi@$hostvdi "tmp=\`mktemp\`; \
                               tar -C $src -czf \$tmp .;\
                               cat \$tmp; \
                               rm \$tmp;" | tar -C $dst -xzf - 
    fi
done

#
# Copy files needed to build container from home directory
# All of these files are optional and will only be copied to the container if they exist.
#
files_to_copy=( \
    ~/.vimrc \
    ~/.bashrc \
    ~/.gitconfig \
    ~/.gitignore \
    ~/.coverity_auth_key \
    "$build_tools/kernel-devel-3.10.0-957.27.2.el7.x86_64.rpm" \
)
for file in ${files_to_copy[@]}; do
    if [ -e $file ] && [ ! -e "./$(basename $file)" ]; then
        cp $file .
    fi
done

#
# Finally build the container using the docker-compose.yml file
#
docker-compose --verbose build bldr
